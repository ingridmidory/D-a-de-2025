{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJxNUBYrWRwv6aY8MHaT1K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ingridmidory/D-a-de-2025/blob/main/Entrenamiento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenando un modelo de CNN"
      ],
      "metadata": {
        "id": "f4io1_ZrHW29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente modelo de redes neuronales convolucionales fue tomado del siguiente github:\n",
        "\n",
        "> **[Clasificador-de-Perros-y-Gatos](https://github.com/Gamapro/Clasificador-de-Perros-y-Gatos)**\n",
        "\n",
        "Este modelo se entrenÃ³ con los datos de entrenamiento y validaciÃ³n que creador del mismo nos proporciona en el github mencionado.\n",
        "\n",
        " Este trabajo fue realizado en el marco de la celebraciÃ³n del ğŸ‰ ***DÃ­a Internacional de las MatemÃ¡ticas*** ğŸ‰ que se llevarÃ¡ a cabo el dÃ­a 14 de marzo del 2025 en las instalaciones de la Escuela Nacional Preparatoria No. 4. Nuestro objetivo es acercar la IA a mÃ¡s personas de una manera prÃ¡ctica y divertida.\n",
        "\n",
        "ğŸ”¹ CrÃ©ditos\n",
        "* Modelo de CNN: Creado por [David Gamaliel Arcos](https://github.com/Gamapro)\n",
        "* Participantes:\n",
        " * [Ingrid Monterroso Alfaro ](https://github.com/ingridmidory)\n",
        " * Ahuacatitan Espindola JosÃ© Luis\n",
        " * De la Cruz Saavedra Uriel\n",
        " * Godoy Santiago JosÃ© Ãngel\n",
        "\n"
      ],
      "metadata": {
        "id": "unyB95qWHdYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense, Activation, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Xetd7qwjfS5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cbhh9l_ZoCG",
        "outputId": "7ec5f640-1cb9-4a0b-f7ee-553318d48583"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir rutas en Google Drive\n",
        "\n",
        "ruta_drive = \"/content/drive/MyDrive/Diadepi /dataset\"  # Cambia esto segÃºn el nombre de tu carpeta\n",
        "data_entrenamiento = \"/content/drive/MyDrive/Diadepi /entrenamiento\" #importante\n",
        "data_validacion = \"/content/drive/MyDrive/Diadepi /validacion\" #importante"
      ],
      "metadata": {
        "id": "uFQZbPJwmgu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parametros\n",
        "\n",
        "epocas = 20\n",
        "altura, longitud = 100,100\n",
        "batch_size = 32\n",
        "batch_size_val = 16\n",
        "pasos = 500\n",
        "pasos_validacion = 100\n",
        "filtrosConv1 = 8\n",
        "filtrosConv2 = 16\n",
        "filtrosConv3 = 32\n",
        "tamano_filtro1 = (8,8)\n",
        "tamano_filtro2 = (4,4)\n",
        "tamano_filtro3 = (2,2)\n",
        "pool = (2,2)\n",
        "clases = 2\n",
        "lr = 0.001"
      ],
      "metadata": {
        "id": "T4wi_g9QntHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesamiento\n",
        "\n",
        "entrenamiento_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,  # Cada pixel este entre 0 y 1\n",
        "    shear_range = 0.2, # Generar las imagenes \"inclinadas\"\n",
        "    #zoom_range = 0.2,  # Zoomearlas parahacer \"enfasis\"\n",
        "    horizontal_flip = True   # Invertir para distinguir direccionalidad\n",
        ")\n",
        "\n",
        "validacion_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255  # Solo reescalado para las imagenes de test\n",
        ")\n",
        "\n",
        "imagen_entrenamiento = entrenamiento_datagen.flow_from_directory(\n",
        "    data_entrenamiento,\n",
        "    target_size = (altura, longitud),\n",
        "    #classes = ['perro','gato'],\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical'\n",
        ")\n",
        "\n",
        "imagen_validacion = validacion_datagen.flow_from_directory(\n",
        "    data_validacion,\n",
        "    target_size = (altura, longitud),\n",
        "    #classes = ['perro','gato'],\n",
        "    batch_size = batch_size_val,\n",
        "    class_mode = 'categorical'\n",
        ")\n",
        "\n",
        "#print(imagen_entrenamiento.class_indices)\n",
        "def plots(ims, figsize=(20,20), rows=1, interp=False, titles=None):\n",
        "    if type(ims[0]) is np.ndarray:\n",
        "        ims = np.array(ims).astype(np.uint8)\n",
        "        if(ims.shape[-1] != 3):\n",
        "            ims = ims.transpose((0,2,3,1))\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    cols = len(ims)//rows if len(ims)%2==0 else len(ims)//rows+1\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows,cols,i+1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None:\n",
        "            sp.set_title(titles[i], fontsize=16)\n",
        "        plt.imshow(ims[i],interpolation=None if interp else \"none\")\n",
        "    plt.show()\n",
        "imgs, labels = next(imagen_entrenamiento)\n",
        "#plots(imgs,titles=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX3149dGn0kD",
        "outputId": "aa931fce-7bad-42ea-e299-b86f64e23f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 980 images belonging to 2 classes.\n",
            "Found 2023 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear la Red Neuronal Convolucional\n",
        "cnn = Sequential()\n",
        "\n",
        "# primera capa\n",
        "cnn.add(Conv2D(filtrosConv1, tamano_filtro1, padding='same', input_shape=(altura,longitud,3), activation='relu'))\n",
        "cnn.add(MaxPooling2D(pool_size=pool))\n",
        "\n",
        "# Segunda Capa\n",
        "cnn.add(Conv2D(filtrosConv2, tamano_filtro2, padding='same', activation='relu'))\n",
        "cnn.add(MaxPooling2D(pool_size=pool))\n",
        "\n",
        "# Tercera Capa\n",
        "cnn.add(Conv2D(filtrosConv3, tamano_filtro3, padding='same', activation='relu'))\n",
        "cnn.add(MaxPooling2D(pool_size=pool))\n",
        "\n",
        "# Volverla plana, Cuarta y Quinta capa\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(4, activation='relu'))\n",
        "cnn.add(Dropout(0.5))\n",
        "cnn.add(Dense(clases, activation='softmax'))\n",
        "\n",
        "# Compilar el modelo\n",
        "cnn.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=lr), metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hxkeIMTpxHP",
        "outputId": "2a95fc33-5221-4d56-aa07-ee862e1f3592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo\n",
        "log_dir = \"logs/{}\".format(time())\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=0)\n",
        "\n",
        "cnn.fit(\n",
        "    imagen_entrenamiento,\n",
        "    steps_per_epoch=pasos,\n",
        "    epochs=epocas,\n",
        "    validation_data=imagen_validacion,\n",
        "    validation_steps=pasos_validacion,\n",
        "    callbacks=[tensorboard_callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdiFunZtrEY6",
        "outputId": "eb2c4aaf-2ba4-430b-d636-f00a06dcd615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m 31/500\u001b[0m \u001b[32mâ”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4:15\u001b[0m 545ms/step - accuracy: 0.5325 - loss: 0.6952"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 936ms/step - accuracy: 0.5279 - loss: 0.6935 - val_accuracy: 0.4988 - val_loss: 0.6933\n",
            "Epoch 2/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 313ms/step - accuracy: 0.5357 - loss: 0.6923 - val_accuracy: 0.5050 - val_loss: 0.6932\n",
            "Epoch 3/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 180ms/step - accuracy: 0.5348 - loss: 0.6918 - val_accuracy: 0.5013 - val_loss: 0.6934\n",
            "Epoch 4/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 66ms/step - accuracy: 0.5337 - loss: 0.6916 - val_accuracy: 0.5006 - val_loss: 0.6936\n",
            "Epoch 5/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 58ms/step - accuracy: 0.5347 - loss: 0.6913 - val_accuracy: 0.5050 - val_loss: 0.6936\n",
            "Epoch 6/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 80ms/step - accuracy: 0.5340 - loss: 0.6912 - val_accuracy: 0.4950 - val_loss: 0.6946\n",
            "Epoch 7/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 56ms/step - accuracy: 0.5346 - loss: 0.6910 - val_accuracy: 0.5088 - val_loss: 0.6935\n",
            "Epoch 8/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 83ms/step - accuracy: 0.5342 - loss: 0.6910 - val_accuracy: 0.4925 - val_loss: 0.6952\n",
            "Epoch 9/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 56ms/step - accuracy: 0.5358 - loss: 0.6908 - val_accuracy: 0.4975 - val_loss: 0.6949\n",
            "Epoch 10/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 81ms/step - accuracy: 0.5345 - loss: 0.6909 - val_accuracy: 0.5013 - val_loss: 0.6946\n",
            "Epoch 11/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 57ms/step - accuracy: 0.5343 - loss: 0.6909 - val_accuracy: 0.4956 - val_loss: 0.6954\n",
            "Epoch 12/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 60ms/step - accuracy: 0.5369 - loss: 0.6906 - val_accuracy: 0.5069 - val_loss: 0.6943\n",
            "Epoch 13/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 78ms/step - accuracy: 0.5339 - loss: 0.6909 - val_accuracy: 0.5013 - val_loss: 0.6949\n",
            "Epoch 14/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 56ms/step - accuracy: 0.5353 - loss: 0.6907 - val_accuracy: 0.4856 - val_loss: 0.6970\n",
            "Epoch 15/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 56ms/step - accuracy: 0.5358 - loss: 0.6907 - val_accuracy: 0.4956 - val_loss: 0.6958\n",
            "Epoch 16/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 137ms/step - accuracy: 0.5344 - loss: 0.6908 - val_accuracy: 0.5019 - val_loss: 0.6950\n",
            "Epoch 17/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 139ms/step - accuracy: 0.5343 - loss: 0.6908 - val_accuracy: 0.5006 - val_loss: 0.6953\n",
            "Epoch 18/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 57ms/step - accuracy: 0.5340 - loss: 0.6909 - val_accuracy: 0.5025 - val_loss: 0.6950\n",
            "Epoch 19/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 139ms/step - accuracy: 0.5332 - loss: 0.6910 - val_accuracy: 0.5044 - val_loss: 0.6947\n",
            "Epoch 20/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 61ms/step - accuracy: 0.5341 - loss: 0.6909 - val_accuracy: 0.5056 - val_loss: 0.6947\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d8a7c7ec710>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo en Google Drive\n",
        "modelo_dir = ruta_drive + \"modelo/\"\n",
        "if not os.path.exists(modelo_dir):\n",
        "    os.mkdir(modelo_dir)\n",
        "\n",
        "cnn.save(modelo_dir + \"modelo_perros_gatos.h5\")\n",
        "cnn.save_weights(modelo_dir + \"pesos_perros_gatos.weights.h5\") # Changed the file extension to .weights.h5\n",
        "\n",
        "print(\"Â¡Entrenamiento completado y modelo guardado en Google Drive!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dr3tY4-crWTA",
        "outputId": "7b3a6a2f-1acb-4040-dc5b-e0819113c722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Â¡Entrenamiento completado y modelo guardado en Google Drive!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "068vW1LGOgLx"
      }
    }
  ]
}